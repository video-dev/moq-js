import { Frame, Component } from "./timeline"
import * as MP4 from "../../media/mp4"
import * as Message from "./message"

interface DecoderConfig {
	codec: string
	description?: ArrayBuffer | Uint8Array | DataView
	codedWidth?: number
	codedHeight?: number
	displayAspectWidth?: number
	displayAspectHeight?: number
	colorSpace?: {
		primaries?: "bt709" | "bt470bg" | "smpte170m"
		transfer?: "bt709" | "smpte170m" | "iec61966-2-1"
		matrix?: "rgb" | "bt709" | "bt470bg" | "smpte170m"
	}
	hardwareAcceleration?: "no-preference" | "prefer-hardware" | "prefer-software"
	optimizeForLatency?: boolean
}

export class Renderer {
	#canvas: OffscreenCanvas
	#timeline: Component

	#decoder!: VideoDecoder
	#queue: TransformStream<Frame, VideoFrame>

	#decoderConfig?: DecoderConfig
	#waitingForKeyframe: boolean = true
	#paused: boolean
	#hasSentWaitingForKeyFrameEvent: boolean = false

	constructor(config: Message.ConfigVideo, timeline: Component) {
		this.#canvas = config.canvas
		this.#timeline = timeline
		this.#paused = false

		this.#queue = new TransformStream({
			start: this.#start.bind(this),
			transform: this.#transform.bind(this),
		})

		this.#run().catch(console.error)
	}

	pause() {
		this.#paused = true
		console.log(`[VideoWorker] pause called, decoder state: ${this.#decoder.state}`)
		this.#decoder.flush().catch((err) => {
			console.error("Failed to flush video decoder on pause:", err)
		})
		this.#waitingForKeyframe = true
	}

	play() {
		this.#paused = false
	}

	async #run() {
		const reader = this.#timeline.frames.pipeThrough(this.#queue).getReader()
		for (;;) {
			const { value: frame, done } = await reader.read()
			if (this.#paused) continue
			if (done) break

			self.requestAnimationFrame(() => {
				this.#canvas.width = frame.displayWidth
				this.#canvas.height = frame.displayHeight

				const ctx = this.#canvas.getContext("2d")
				if (!ctx) throw new Error("failed to get canvas context")

				ctx.drawImage(frame, 0, 0, frame.displayWidth, frame.displayHeight) // TODO respect aspect ratio
				frame.close()
			})
		}
	}

	#start(controller: TransformStreamDefaultController<VideoFrame>) {
		this.#decoder = new VideoDecoder({
			output: (frame: VideoFrame) => {
				controller.enqueue(frame)
			},
			error: (e: Error) => {
				console.error("VideoDecoder error:", e)
			},
		})
	}

	#transform(frame: Frame) {
		console.log(
			`[VideoWorker] #transform received frame. track: ${frame.track.codec}, sync: ${frame.sample.is_sync}, state: ${this.#decoder.state}`,
		)

		if (this.#decoder.state === "closed" || this.#paused) {
			console.warn("[VideoWorker] Decoder is closed or paused. Skipping frame.")
			return
		}

		const { sample, track } = frame

		// Reset the decoder on video track change
		if (this.#decoderConfig && this.#decoder.state == "configured") {
			if (MP4.isVideoTrack(track)) {
				const configMismatch =
					this.#decoderConfig.codec !== track.codec ||
					this.#decoderConfig.codedWidth !== track.video.width ||
					this.#decoderConfig.codedHeight !== track.video.height

				if (configMismatch) {
					this.#decoder.reset()
					this.#decoderConfig = undefined
				}
			}
		}

		// Configure the decoder with the first frame
		if (this.#decoder.state !== "configured") {
			console.log("[VideoWorker] Decoder is not configured. Attempting to configure.")

			const desc = sample.description
			console.log("[VideoWorker] Received init segment description:", desc)
			const box = desc.avcC ?? desc.hvcC ?? desc.vpcC ?? desc.av1C
			if (!box) {
				console.error(
					"[VideoWorker] FAILED: No valid codec configuration box (avcC, etc.) found in init segment.",
				)
				throw new Error(`unsupported codec: ${track.codec}`)
			}

			const buffer = new MP4.Stream(undefined, 0, MP4.Stream.BIG_ENDIAN)
			box.write(buffer)
			const description = new Uint8Array(buffer.buffer, 8) // Remove the box header.

			if (!MP4.isVideoTrack(track)) throw new Error("expected video track")

			this.#decoderConfig = {
				codec: track.codec,
				codedHeight: track.video.height,
				codedWidth: track.video.width,
				description,
				// optimizeForLatency: true
			}

			console.log("[VideoWorker] Configuring decoder with:", this.#decoderConfig)

			try {
				this.#decoder.configure(this.#decoderConfig)
				console.log(`[VideoWorker] Decoder configured successfully. New state: ${this.#decoder.state}`)
			} catch (e) {
				console.error("[VideoWorker] FAILED to configure decoder:", e)
				return // Stop processing if configure fails
			}

			if (!frame.sample.is_sync) {
				this.#waitingForKeyframe = true
			} else {
				this.#waitingForKeyframe = false
			}
		}

		//At the start of decode , VideoDecoder seems to expect a key frame after configure() or flush()
		if (this.#decoder.state == "configured") {
			if (this.#waitingForKeyframe && !frame.sample.is_sync) {
				console.warn("Skipping non-keyframe until a keyframe is found.")
				if (!this.#hasSentWaitingForKeyFrameEvent) {
					self.postMessage("waitingforkeyframe")
					this.#hasSentWaitingForKeyFrameEvent = true
				}
				return
			}

			// On arrival of a keyframe, allow decoding and stop waiting for a keyframe.
			if (frame.sample.is_sync) {
				this.#waitingForKeyframe = false
				this.#hasSentWaitingForKeyFrameEvent = false
			}

			const chunk = new EncodedVideoChunk({
				type: frame.sample.is_sync ? "key" : "delta",
				data: frame.sample.data,
				timestamp: frame.sample.dts / frame.track.timescale,
			})

			console.log(`[VideoWorker] Decoding chunk, type: ${chunk.type}, size: ${chunk.byteLength}`)
			try {
				this.#decoder.decode(chunk)
			} catch (e) {
				console.error("[VideoWorker] FAILED to decode chunk:", e)
			}
		}
	}
}
